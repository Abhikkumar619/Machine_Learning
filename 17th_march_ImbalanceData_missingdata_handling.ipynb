{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4af7d05-cc91-4e3d-8cd7-2c55e2cb818a",
   "metadata": {},
   "source": [
    "Q1: What are missing values in a dataset? Why is it essential to handle missing values? Name some\n",
    "algorithms that are not affected by missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d37980-7351-4ca1-9940-c97b19ca60cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Missing value is define as the value or data that is not stored for some variable in given dataset is missing value.\n",
    "\n",
    "It is important to handle the missing value in dataset because.\n",
    "\n",
    "1. Prevents biased results: When missing values are present in a dataset it leas to biased result.\n",
    "2. missing value lead to incorrect estimates of the mean, variance, and correlation between variables.\n",
    "3. Missing value can cauese error in statistical analyses, such as correlations and regression analysis. \n",
    "4. Handling value value can improve the validity of research findings .\n",
    "\n",
    "Random Forest algorithm is not affected by missing value.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519266ce-0979-4382-87c8-ef43773a41ba",
   "metadata": {},
   "source": [
    "Q2: List down techniques used to handle missing data. Give an example of each with python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a810fd-f1ee-4867-aab0-9e68a3750041",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Some techniques used to handle missing data are: \n",
    "1. Mean value imputation.\n",
    "2. Medium value imputation\n",
    "3. Mode imputation.\n",
    "\n",
    "\n",
    "Example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38d94bd9-fff4-444a-b145-ec333ced3372",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1578ce2e-50d1-4a74-bc3e-c006d0940115",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=sns.load_dataset('titanic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13adfd19-bb9a-4767-8c12-cb0f2384995a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
       "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
       "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
       "\n",
       "     who  adult_male deck  embark_town alive  alone  \n",
       "0    man        True  NaN  Southampton    no  False  \n",
       "1  woman       False    C    Cherbourg   yes  False  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fdcfdd0-f7c8-46fb-b845-3d8a8240273d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived         0\n",
       "pclass           0\n",
       "sex              0\n",
       "age            177\n",
       "sibsp            0\n",
       "parch            0\n",
       "fare             0\n",
       "embarked         2\n",
       "class            0\n",
       "who              0\n",
       "adult_male       0\n",
       "deck           688\n",
       "embark_town      2\n",
       "alive            0\n",
       "alone            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1873be1-0373-40eb-a8bc-82141628b67d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['age'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5c36dbe-e6b9-43e2-a687-4dfc79a2f63f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.69911764705882"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['age'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bbcf80e5-b058-466f-8368-caf86d89a665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean imputation\n",
    "df['age_mean']=df['age'].fillna(df['age'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84e0f2e5-e437-43e1-9b3e-04cbcc69a3e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C    59\n",
       "B    47\n",
       "D    33\n",
       "E    32\n",
       "A    15\n",
       "F    13\n",
       "G     4\n",
       "Name: deck, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['deck'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7fbd95d6-c941-4596-9ee0-990e8fd7aee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mode imputation\n",
    "df['deck_mode']=df['deck'].fillna(df['deck'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8d08c40d-b2b1-4158-808d-ca8f9e0feffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Median imputation.\n",
    "df['age_median']=df['age'].fillna(df['age'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5729b945-fa6d-4008-b0c6-d999021c37fb",
   "metadata": {},
   "source": [
    "Q3: Explain the imbalanced data. What will happen if imbalanced data is not handled?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c17a1a-9eda-4484-9d5d-14061be3bc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A imbalance dataset refers to a dataset whose distribution of labels is highly unequal is imbalanced dataset.\n",
    "\n",
    "If imbalanced dataset is not handled than it cause biased and inaccurate machine learning models.\n",
    "if one class has majority data and another has minority data than machine learning algorithm to biased towards the majority class and ignore the minority, classes\n",
    "so that to make machine learning models free from imblanced dataset our module work accurate and unbiased theit predictions.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecdba5f-c3d3-4f59-92ff-71111294dc87",
   "metadata": {},
   "source": [
    "Q4: What are Up-sampling and Down-sampling? Explain with an example when up-sampling and down-\n",
    "sampling are required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359f337f-ce05-43c1-a7da-07f0155f1615",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Up-sampling: \n",
    "This technique attempts to increase the size of rare sample to create a balance when data is insuffiecnt.\n",
    "\n",
    "when to use up-sampling:\n",
    "lets have a classification probelm with two classes and 100k data point and 20 K data point are positive and 80 k are negative. The positive \n",
    "class is minority class and 80k is majority class. 20 k data point ness to be oversampled. replicated them four times to produce 80k. This yields \n",
    "an equal number of example for both negative classes . the size of dataset would increase to 160k as a result.\n",
    "\n",
    "Down-sampling: \n",
    "This technique attempts to decrease the size or must sample to create balance dataset when data is suffient.\n",
    "\n",
    "when to use Down-sampling: \n",
    "suppose we have two classes A and B having data point A= 50K and B= 10K. to balance data according to B datapoint. All we need to decrease the A\n",
    "by 5 times . This yields an equal number of example and total size of dataset 20K .\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d138621a-fd54-4372-b3e6-26ca8393b667",
   "metadata": {},
   "source": [
    "Q5: What is data Augmentation? Explain SMOTE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f885433-2b6b-4542-a57b-abd78c7daf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Data augmentation is set of technique to artifically increase the new data from existing dataset.\n",
    "\n",
    "SMOTE\n",
    "It is techique used in machine learning to address imbalanced dataset. where the minority class has significantly fewer instances than majority\n",
    "class. SMOTE invloves generating synthetic instances of the minority class bu inerpolating between existing instance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5911bd3-83d4-4c9b-a0a0-77bdb4a94646",
   "metadata": {},
   "source": [
    "Q6: What are outliers in a dataset? Why is it essential to handle outliers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b6a57c-7d29-415f-aeb7-8587b27258de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Outlier is extremly high or extermly low data point relative to nearest dataset is knowns as Outlier.\n",
    "\n",
    "Handling outliers in a dataset is essential because outlier can significantly affect\n",
    "the statistical properties of the dataset and can caluse probelms with machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0eec8f7-2c51-4059-af9b-ed8328d7f2f8",
   "metadata": {},
   "source": [
    "Q7: You are working on a project that requires analyzing customer data. However, you notice that some of\n",
    "the data is missing. What are some techniques you can use to handle the missing data in your analysis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e87aa7-9539-47fc-be8d-c55392b37a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "To handle the missing data in customer dataset. All i do is filling the missing data by avaliable data. the tchnique used to \n",
    "handle the missing value which are mean imputation , median imputation , mode imputation. For numerical data if data is normal \n",
    "distributed we use mean imputation. \n",
    "if the data is numerical and having outlier in dataset than we use median imputataion.\n",
    "if data is categorical the we use mode imputation.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902f3beb-214f-4a6f-9d0f-213b7e166ad4",
   "metadata": {},
   "source": [
    "Q8: You are working with a large dataset and find that a small percentage of the data is missing. What are\n",
    "some strategies you can use to determine if the missing data is missing at random or if there is a pattern\n",
    "to the missing data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0622b8-2178-4c66-8ab2-78cf47c69d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "There are several strategies that can used to determine if the missing data is missing at random or if there is pattern to the missing data\n",
    "are:\n",
    "1. Visual inspection:  plotting the data using heatmap or scatterplot which helps to identify missing data.\n",
    "2. Summary statistics: This invloves calculating summary statistics for variables with missing data and comparing them to variables with complete  data. This\n",
    "                      can help identify any systematic differences in the missing data.\n",
    "\n",
    "3. Little test: This invloves testing for presence of missing completely at random using statistical test such as little's test. This check if missing data\n",
    "   is unrelated to the observed data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5db4db-484a-4cad-9e59-1cd6cd2da020",
   "metadata": {},
   "source": [
    "Q9: Suppose you are working on a medical diagnosis project and find that the majority of patients in the\n",
    "dataset do not have the condition of interest, while a small percentage do. What are some strategies you\n",
    "can use to evaluate the performance of your machine learning model on this imbalanced dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3df1fe-1ce6-472a-b56d-4bb94bc754f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The strategies which is used to evaluate the performance of machine learning model in imbalanced dataset are resample technique such as \n",
    "upsampling which we have rare data and down sampling technique when we have sufficent data present and SMOTE technique are used to handle the imbalance dataset.\n",
    "This help to improve the machine learning model by giving traning data.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f141568f-f787-41f8-9bef-c5be05e60222",
   "metadata": {},
   "source": [
    "\n",
    "Q10: When attempting to estimate customer satisfaction for a project, you discover that the dataset is\n",
    "unbalanced, with the bulk of customers reporting being satisfied. What methods can you employ to\n",
    "balance the dataset and down-sample the majority class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d11bee-5956-4439-a33b-9d20fc3cb946",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Synthetic minority oversampling technique (SMOTE): This involves generating synthetic examples for the minority class by interpolating between examples\n",
    "from the minority class. This can help increase the size of the minority class and balance the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266c941a-a0fe-45ea-b411-0b2e5a9214ea",
   "metadata": {},
   "source": [
    "Q11: You discover that the dataset is unbalanced with a low percentage of occurrences while working on a\n",
    "project that requires you to estimate the occurrence of a rare event. What methods can you employ to\n",
    "balance the dataset and up-sample the minority class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c68ec7-bb3a-4938-b736-dcc7500227fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Random over-sampling: This involves randomly duplicating examples from the minority class to balance the dataset. However,\n",
    "                    this method can result in overfitting and may not be the best option if the dataset is small.\n",
    "\n",
    "Synthetic minority oversampling technique (SMOTE): This involves generating synthetic examples for the minority class by interpolating between examples from the minority class.\n",
    "                                                   This can help increase the size of the minority class and balance the dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
